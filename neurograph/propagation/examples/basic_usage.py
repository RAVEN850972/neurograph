# neurograph/propagation/examples/basic_usage.py
"""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ NeuroGraph.

–≠—Ç–æ—Ç —Ñ–∞–π–ª –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª—è propagation,
–≤–∫–ª—é—á–∞—è —Å–æ–∑–¥–∞–Ω–∏–µ –¥–≤–∏–∂–∫–æ–≤, –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è
–∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
"""

import numpy as np
from typing import Dict, List
import time

# –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è
from neurograph.propagation import (
    create_default_engine, create_default_config, create_fast_config,
    PropagationConfigBuilder, PropagationFactory, 
    ActivationFunction, DecayFunction, PropagationMode,
    quick_propagate, scenario_concept_exploration,
    scenario_knowledge_activation, scenario_semantic_similarity,
    propagate_and_visualize, debug_propagation
)

# –ò–º–ø–æ—Ä—Ç—ã –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª–µ–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
from neurograph.semgraph import SemGraphFactory


def example_basic_propagation():
    """–ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏."""
    
    print("=== –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ===")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –≥—Ä–∞—Ñ–∞
    graph = SemGraphFactory.create("memory_efficient")
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤
    concepts = [
        ("python", {"type": "programming_language", "popularity": "high"}),
        ("programming", {"type": "activity", "domain": "computer_science"}),
        ("computer_science", {"type": "field", "level": "academic"}),
        ("artificial_intelligence", {"type": "field", "level": "research"}),
        ("machine_learning", {"type": "subdomain", "parent": "artificial_intelligence"}),
        ("neural_networks", {"type": "technique", "parent": "machine_learning"}),
        ("deep_learning", {"type": "technique", "parent": "neural_networks"}),
        ("data_science", {"type": "field", "level": "applied"}),
        ("statistics", {"type": "field", "level": "mathematical"}),
        ("mathematics", {"type": "field", "level": "fundamental"})
    ]
    
    for concept, attributes in concepts:
        graph.add_node(concept, **attributes)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–≤—è–∑–µ–π
    relations = [
        ("python", "programming", "used_for", 0.9),
        ("programming", "computer_science", "part_of", 0.8),
        ("artificial_intelligence", "computer_science", "part_of", 0.9),
        ("machine_learning", "artificial_intelligence", "part_of", 0.9),
        ("neural_networks", "machine_learning", "technique_of", 0.8),
        ("deep_learning", "neural_networks", "extension_of", 0.9),
        ("machine_learning", "data_science", "used_in", 0.7),
        ("data_science", "statistics", "based_on", 0.8),
        ("statistics", "mathematics", "part_of", 0.9),
        ("python", "data_science", "used_for", 0.8),
        ("python", "machine_learning", "used_for", 0.9)
    ]
    
    for source, target, relation_type, weight in relations:
        graph.add_edge(source, target, relation_type, weight=weight)
    
    print(f"–°–æ–∑–¥–∞–Ω –≥—Ä–∞—Ñ —Å {len(graph.get_all_nodes())} —É–∑–ª–∞–º–∏ –∏ {len(graph.get_all_edges())} —Å–≤—è–∑—è–º–∏")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–≤–∏–∂–∫–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    engine = create_default_engine(graph)
    config = create_default_config()
    
    # –ù–∞—á–∞–ª—å–Ω—ã–µ —É–∑–ª—ã –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
    initial_nodes = {
        "python": 1.0,
        "machine_learning": 0.8
    }
    
    print(f"–ù–∞—á–∞–ª—å–Ω—ã–µ —É–∑–ª—ã: {initial_nodes}")
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è
    start_time = time.time()
    result = engine.propagate(initial_nodes, config)
    end_time = time.time()
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if result.success:
        print(f"‚úì –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {end_time - start_time:.3f}—Å")
        print(f"  –ò—Ç–µ—Ä–∞—Ü–∏–π: {result.iterations_used}")
        print(f"  –°—Ö–æ–¥–∏–º–æ—Å—Ç—å: {'–î–∞' if result.convergence_achieved else '–ù–µ—Ç'}")
        print(f"  –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤: {len(result.activated_nodes)}")
        print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è: {result.max_activation_reached:.3f}")
        
        print("\n–¢–æ–ø-5 –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤:")
        top_nodes = result.get_most_activated_nodes(5)
        for node_id, activation_level in top_nodes:
            depth = result.activated_nodes[node_id].propagation_depth
            print(f"  {node_id}: {activation_level:.3f} (–≥–ª—É–±–∏–Ω–∞: {depth})")
    else:
        print(f"‚úó –û—à–∏–±–∫–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è: {result.error_message}")
    
    return graph, result


def example_different_configurations():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π."""
    
    print("\n=== –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π ===")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä–∞—Ñ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
    graph, _ = example_basic_propagation()
    
    initial_nodes = {"python": 1.0}
    
    # –†–∞–∑–ª–∏—á–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    configs = {
        "–ë—ã—Å—Ç—Ä–∞—è": create_fast_config(),
        "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é": create_default_config(),
        "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è": PropagationConfigBuilder().reset()
            .set_performance_mode("precise")
            .set_activation_function(ActivationFunction.TANH)
            .set_decay_function(DecayFunction.POWER)
            .set_lateral_inhibition(True, strength=0.3)
            .build()
    }
    
    engine = create_default_engine(graph)
    results = {}
    
    for config_name, config in configs.items():
        print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {config_name}")
        
        engine.reset_activations()
        start_time = time.time()
        result = engine.propagate(initial_nodes, config)
        end_time = time.time()
        
        results[config_name] = {
            "result": result,
            "time": end_time - start_time
        }
        
        if result.success:
            print(f"  ‚úì –í—Ä–µ–º—è: {end_time - start_time:.3f}—Å")
            print(f"  ‚úì –ò—Ç–µ—Ä–∞—Ü–∏–π: {result.iterations_used}")
            print(f"  ‚úì –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤: {len(result.activated_nodes)}")
            print(f"  ‚úì –°—Ö–æ–¥–∏–º–æ—Å—Ç—å: {'–î–∞' if result.convergence_achieved else '–ù–µ—Ç'}")
        else:
            print(f"  ‚úó –û—à–∏–±–∫–∞: {result.error_message}")
    
    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    print("\n--- –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ ---")
    print(f"{'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è':<15} {'–í—Ä–µ–º—è (—Å)':<10} {'–ò—Ç–µ—Ä–∞—Ü–∏–π':<10} {'–£–∑–ª–æ–≤':<8} {'–°—Ö–æ–¥–∏–º–æ—Å—Ç—å'}")
    print("-" * 65)
    
    for config_name, data in results.items():
        result = data["result"]
        if result.success:
            convergence = "–î–∞" if result.convergence_achieved else "–ù–µ—Ç"
            print(f"{config_name:<15} {data['time']:<10.3f} {result.iterations_used:<10} "
                  f"{len(result.activated_nodes):<8} {convergence}")
        else:
            print(f"{config_name:<15} {'–û—à–∏–±–∫–∞':<10} {'-':<10} {'-':<8} {'-'}")


def example_propagation_modes():
    """–ü—Ä–∏–º–µ—Ä —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è."""
    
    print("\n=== –†–∞–∑–ª–∏—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è ===")
    
    graph, _ = example_basic_propagation()
    initial_nodes = {"artificial_intelligence": 1.0}
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
    modes = [
        PropagationMode.SPREADING,
        PropagationMode.FOCUSING, 
        PropagationMode.BIDIRECTIONAL,
        PropagationMode.CONSTRAINED
    ]
    
    engine = create_default_engine(graph)
    
    for mode in modes:
        print(f"\n–†–µ–∂–∏–º: {mode.value}")
        
        config = PropagationConfigBuilder().reset()\
            .set_propagation_mode(mode)\
            .set_activation_limits(threshold=0.15, max_nodes=50)\
            .build()
        
        engine.reset_activations()
        result = engine.propagate(initial_nodes, config)
        
        if result.success:
            print(f"  –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤: {len(result.activated_nodes)}")
            print(f"  –ò—Ç–µ—Ä–∞—Ü–∏–π: {result.iterations_used}")
            print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è: {result.max_activation_reached:.3f}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 —É–∑–ª–∞
            top_nodes = result.get_most_activated_nodes(3)
            print("  –¢–æ–ø-3 —É–∑–ª–∞:")
            for node_id, activation_level in top_nodes:
                if node_id != "artificial_intelligence":  # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —É–∑–µ–ª
                    print(f"    {node_id}: {activation_level:.3f}")
        else:
            print(f"  –û—à–∏–±–∫–∞: {result.error_message}")


def example_scenario_usage():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–æ—Ç–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤."""
    
    print("\n=== –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ ===")
    
    graph, _ = example_basic_propagation()
    
    # –°—Ü–µ–Ω–∞—Ä–∏–π 1: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ç–∞
    print("\n1. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ç–∞ 'machine_learning':")
    exploration_result = scenario_concept_exploration(
        graph, "machine_learning", exploration_depth=3
    )
    
    if "error" not in exploration_result:
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤: {len(exploration_result['related_concepts'])}")
        print("   –¢–æ–ø-3 —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–∞:")
        for concept in exploration_result['related_concepts'][:3]:
            print(f"     {concept['concept']}: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å {concept['relevance']:.3f}, "
                  f"—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ {concept['distance']}")
    else:
        print(f"   –û—à–∏–±–∫–∞: {exploration_result['error']}")
    
    # –°—Ü–µ–Ω–∞—Ä–∏–π 2: –ê–∫—Ç–∏–≤–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π
    print("\n2. –ê–∫—Ç–∏–≤–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É ['python', 'data_science']:")
    activation_result = scenario_knowledge_activation(
        graph, ["python", "data_science"], focus_mode=True
    )
    
    if "error" not in activation_result:
        knowledge = activation_result['activated_knowledge']
        print(f"   –û—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤: {len(knowledge['primary'])}")
        print(f"   –í—Ç–æ—Ä–∏—á–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤: {len(knowledge['secondary'])}")
        print(f"   –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π: {len(knowledge['connections'])}")
        print(f"   –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤: {len(knowledge['insights'])}")
        
        if knowledge['primary']:
            print("   –¢–æ–ø-3 –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–∞:")
            for concept in knowledge['primary'][:3]:
                print(f"     {concept['concept']}: –∞–∫—Ç–∏–≤–∞—Ü–∏—è {concept['activation_level']:.3f}")
    else:
        print(f"   –û—à–∏–±–∫–∞: {activation_result['error']}")
    
    # –°—Ü–µ–Ω–∞—Ä–∏–π 3: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å
    print("\n3. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å –º–µ–∂–¥—É 'python' –∏ 'statistics':")
    similarity_result = scenario_semantic_similarity(
        graph, "python", "statistics", max_depth=4
    )
    
    if "error" not in similarity_result:
        print(f"   –û–±—â–∞—è –±–ª–∏–∑–æ—Å—Ç—å: {similarity_result['overall_similarity']:.3f}")
        print(f"   –£—Ä–æ–≤–µ–Ω—å –±–ª–∏–∑–æ—Å—Ç–∏: {similarity_result['analysis']['similarity_level']}")
        print(f"   –°–∏–ª–∞ —Å–≤—è–∑–∏: {similarity_result['analysis']['connection_strength']}")
        print(f"   –û–±—â–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤: {similarity_result['similarity_metrics']['concept_overlap_count']}")
        
        if similarity_result['common_concepts']:
            print("   –¢–æ–ø-3 –æ–±—â–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ç–∞:")
            for concept in similarity_result['common_concepts'][:3]:
                print(f"     {concept['concept']}: –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è {concept['combined_activation']:.3f}")
    else:
        print(f"   –û—à–∏–±–∫–∞: {similarity_result['error']}")


def example_visualization():
    """–ü—Ä–∏–º–µ—Ä –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è."""
    
    print("\n=== –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===")
    
    graph, _ = example_basic_propagation()
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    initial_nodes = {"computer_science": 1.0}
    
    print("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π...")
    
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é (–º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å—Ä–µ–¥–∞—Ö)
        result = propagate_and_visualize(
            graph, 
            initial_nodes, 
            config_preset="balanced",
            save_path="propagation_result.png",
            show_animation=False
        )
        
        if result.success:
            print("‚úì –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ 'propagation_result.png'")
        else:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {result.error_message}")
    
    except Exception as e:
        print(f"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–≤–æ–∑–º–æ–∂–Ω–æ, –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç matplotlib): {e}")
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        engine = create_default_engine(graph)
        config = create_default_config()
        result = engine.propagate(initial_nodes, config)
        
        if result.success:
            print("\n–¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
            print("–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É–∑–ª—ã –ø–æ —É—Ä–æ–≤–Ω—è–º:")
            
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –≥–ª—É–±–∏–Ω–µ
            by_depth = {}
            for node_id, activation in result.activated_nodes.items():
                depth = activation.propagation_depth
                if depth not in by_depth:
                    by_depth[depth] = []
                by_depth[depth].append((node_id, activation.activation_level))
            
            for depth in sorted(by_depth.keys()):
                print(f"  –ì–ª—É–±–∏–Ω–∞ {depth}:")
                nodes_at_depth = sorted(by_depth[depth], key=lambda x: x[1], reverse=True)
                for node_id, activation_level in nodes_at_depth:
                    print(f"    {node_id}: {activation_level:.3f}")


def example_integration_with_other_modules():
    """–ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –¥—Ä—É–≥–∏–º–∏ –º–æ–¥—É–ª—è–º–∏ NeuroGraph."""
    
    print("\n=== –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ –º–æ–¥—É–ª—è–º–∏ ===")
    
    graph, _ = example_basic_propagation()
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
    engine = create_default_engine(graph)
    config = create_default_config()
    initial_nodes = {"python": 1.0, "data_science": 0.7}
    
    result = engine.propagate(initial_nodes, config)
    
    if not result.success:
        print(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è: {result.error_message}")
        return
    
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–ª—É—á–µ–Ω, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é:")
    
    # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å SemGraph (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)
    print("\n1. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å SemGraph:")
    
    from neurograph.propagation import integrate_with_semgraph
    integrate_with_semgraph(result, graph)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    updated_nodes = 0
    for node_id in result.activated_nodes.keys():
        node_data = graph.get_node(node_id)
        if node_data and "last_activation_level" in node_data:
            updated_nodes += 1
    
    print(f"   –û–±–Ω–æ–≤–ª–µ–Ω–æ —É–∑–ª–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: {updated_nodes}")
    
    # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Memory (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω –º–æ–¥—É–ª—å)
    print("\n2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Memory:")
    
    try:
        from neurograph.memory import create_default_biomorphic_memory
        from neurograph.propagation import integrate_with_memory
        
        memory = create_default_biomorphic_memory()
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —ç–Ω–∫–æ–¥–µ—Ä-–∑–∞–≥–ª—É—à–∫—É
        class MockEncoder:
            def encode(self, text):
                return np.random.random(384)
        
        encoder = MockEncoder()
        integrate_with_memory(result, memory, encoder)
        
        print(f"   –î–æ–±–∞–≤–ª–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –ø–∞–º—è—Ç—å: {memory.size()}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–∑ –ø–∞–º—è—Ç–∏
        recent_items = memory.get_recent_items(hours=1.0)
        print(f"   –ù–µ–¥–∞–≤–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(recent_items)}")
        
        for item in recent_items[:3]:
            print(f"     {item.content} (—Ç–∏–ø: {item.content_type})")
    
    except ImportError:
        print("   –ú–æ–¥—É–ª—å Memory –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
    
    # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Processor (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω –º–æ–¥—É–ª—å)
    print("\n3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Processor:")
    
    try:
        from neurograph.propagation import integrate_with_processor
        
        # –°–æ–∑–¥–∞–µ–º mock –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        class MockProcessor:
            def __init__(self):
                self.contexts = []
            
            def process_context(self, context):
                self.contexts.append(context)
                return context
        
        processor = MockProcessor()
        context = integrate_with_processor(result, processor)
        
        print(f"   –°–æ–∑–¥–∞–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å {len(context.facts)} —Ñ–∞–∫—Ç–∞–º–∏")
        print("   –ü—Ä–∏–º–µ—Ä—ã —Ñ–∞–∫—Ç–æ–≤ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏:")
        
        fact_examples = list(context.facts.items())[:3]
        for fact_key, fact_data in fact_examples:
            print(f"     {fact_key}: {fact_data}")
    
    except ImportError:
        print("   –ú–æ–¥—É–ª—å Processor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")


def example_performance_analysis():
    """–ü—Ä–∏–º–µ—Ä –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏."""
    
    print("\n=== –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ===")
    
    graph, _ = example_basic_propagation()
    
    # –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_configs = {
        "fast": PropagationConfigBuilder().reset().set_performance_mode("fast").build(),
        "balanced": PropagationConfigBuilder().reset().set_performance_mode("balanced").build(),
        "precise": PropagationConfigBuilder().reset().set_performance_mode("precise").build()
    }
    
    initial_nodes = {"computer_science": 1.0}
    
    print("–ë–µ–Ω—á–º–∞—Ä–∫ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π:")
    
    from neurograph.propagation import benchmark_config
    
    for config_name, config in test_configs.items():
        print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {config_name}")
        
        benchmark_result = benchmark_config(config, graph, initial_nodes, runs=3)
        
        if benchmark_result["success_rate"] > 0:
            print(f"  –£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤: {benchmark_result['successful_runs']}/{benchmark_result['total_runs']}")
            print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {benchmark_result['avg_processing_time']:.3f}—Å")
            print(f"  –°—Ä–µ–¥–Ω–∏–µ –∏—Ç–µ—Ä–∞—Ü–∏–∏: {benchmark_result['avg_iterations']:.1f}")
            print(f"  –ß–∞—Å—Ç–æ—Ç–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏: {benchmark_result['convergence_rate']:.1%}")
            print(f"  –°—Ä–µ–¥–Ω–µ–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤: {benchmark_result['avg_activated_nodes']:.1f}")
        else:
            print(f"  –í—Å–µ –∑–∞–ø—É—Å–∫–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –Ω–µ—É–¥–∞—á–µ–π")
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    print("\n–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")
    
    debug_result = debug_propagation(graph, initial_nodes)
    
    print(f"  –ì—Ä–∞—Ñ: {debug_result['input_analysis']['graph_info']['node_count']} —É–∑–ª–æ–≤, "
          f"{debug_result['input_analysis']['graph_info']['edge_count']} —Å–≤—è–∑–µ–π")
    
    config_analysis = debug_result['config_analysis']
    print(f"  –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {config_analysis['performance_rating']}")
    print(f"  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {config_analysis['memory_usage_estimate']}")
    print(f"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏: {config_analysis['convergence_likelihood']}")
    
    if config_analysis['warnings']:
        print("  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
        for warning in config_analysis['warnings']:
            print(f"    - {warning}")
    
    if config_analysis['recommendations']:
        print("  –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        for recommendation in config_analysis['recommendations']:
            print(f"    - {recommendation}")


def example_custom_activation_functions():
    """–ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–∏—è –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏."""
    
    print("\n=== –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ===")
    
    graph, _ = example_basic_propagation()
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
    activation_functions = [
        ActivationFunction.SIGMOID,
        ActivationFunction.TANH,
        ActivationFunction.RELU,
        ActivationFunction.THRESHOLD,
        ActivationFunction.GAUSSIAN
    ]
    
    initial_nodes = {"machine_learning": 1.0}
    
    print("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏:")
    
    for func in activation_functions:
        print(f"\n–§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: {func.value}")
        
        config = PropagationConfigBuilder().reset()\
            .set_activation_function(func)\
            .set_performance_mode("balanced")\
            .build()
        
        if func == ActivationFunction.THRESHOLD:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ—Ä–æ–≥–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
            config.activation_params = {"threshold": 0.5, "output_high": 1.0, "output_low": 0.0}
        elif func == ActivationFunction.GAUSSIAN:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≥–∞—É—Å—Å–æ–≤—Å–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
            config.activation_params = {"center": 0.5, "width": 0.3, "amplitude": 1.0}
        elif func == ActivationFunction.RELU:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è ReLU
            config.activation_params = {"threshold": 0.1, "max_value": 1.0}
        
        engine = create_default_engine(graph)
        result = engine.propagate(initial_nodes, config)
        
        if result.success:
            active_nodes = len([a for a in result.activated_nodes.values() if a.activation_level > 0.1])
            max_activation = result.max_activation_reached
            
            print(f"  –ê–∫—Ç–∏–≤–Ω—ã—Ö —É–∑–ª–æ–≤: {active_nodes}")
            print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è: {max_activation:.3f}")
            print(f"  –ò—Ç–µ—Ä–∞—Ü–∏–π: {result.iterations_used}")
            print(f"  –°—Ö–æ–¥–∏–º–æ—Å—Ç—å: {'–î–∞' if result.convergence_achieved else '–ù–µ—Ç'}")
        else:
            print(f"  –û—à–∏–±–∫–∞: {result.error_message}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤."""
    
    print("üß† –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª—è Propagation NeuroGraph")
    print("=" * 60)
    
    try:
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã
        example_basic_propagation()
        example_different_configurations()
        example_propagation_modes()
        
        # –ì–æ—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
        example_scenario_usage()
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å—Ä–µ–¥–∞—Ö)
        example_visualization()
        
        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ –º–æ–¥—É–ª—è–º–∏
        example_integration_with_other_modules()
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        example_performance_analysis()
        
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
        example_custom_activation_functions()
        
        print("\n" + "=" * 60)
        print("‚úÖ –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        print("\n–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
        print("- –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π")
        print("- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
        print("- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∑–∞—Ç—É—Ö–∞–Ω–∏—è")
        print("- –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã")
        print("- –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Ä–µ–∞–ª—å–Ω—ã–º –±–∞–∑–∞–º –∑–Ω–∞–Ω–∏–π")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()


# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

def create_larger_test_graph(size: int = 50):
    """–°–æ–∑–¥–∞–Ω–∏–µ –±–æ–ª—å—à–µ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –≥—Ä–∞—Ñ–∞ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤."""
    
    graph = SemGraphFactory.create("memory_efficient")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —É–∑–ª–æ–≤
    domains = ["science", "technology", "art", "philosophy", "mathematics"]
    
    node_id = 0
    for domain in domains:
        # –ö–æ—Ä–Ω–µ–≤–æ–π —É–∑–µ–ª –¥–æ–º–µ–Ω–∞
        root_id = f"{domain}_root"
        graph.add_node(root_id, type="domain", level=0, domain=domain)
        
        # –ü–æ–¥—É–∑–ª—ã –¥–æ–º–µ–Ω–∞
        for level in range(1, 4):  # 3 —É—Ä–æ–≤–Ω—è –≥–ª—É–±–∏–Ω—ã
            level_size = max(1, size // (len(domains) * level))
            
            for i in range(level_size):
                node_name = f"{domain}_l{level}_n{i}"
                graph.add_node(node_name, type="concept", level=level, domain=domain)
                
                # –°–≤—è–∑–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º —É—Ä–æ–≤–Ω–µ–º
                if level == 1:
                    graph.add_edge(root_id, node_name, "contains", weight=0.8)
                else:
                    # –°–≤—è–∑—å —Å —Å–ª—É—á–∞–π–Ω—ã–º —É–∑–ª–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —É—Ä–æ–≤–Ω—è
                    prev_level_nodes = [
                        n for n in graph.get_all_nodes() 
                        if n.startswith(f"{domain}_l{level-1}")
                    ]
                    if prev_level_nodes:
                        parent = np.random.choice(prev_level_nodes)
                        graph.add_edge(parent, node_name, "contains", weight=0.7)
                
                # –°–ª—É—á–∞–π–Ω—ã–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏ –æ–¥–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
                if np.random.random() < 0.3:
                    same_level_nodes = [
                        n for n in graph.get_all_nodes() 
                        if n.startswith(f"{domain}_l{level}") and n != node_name
                    ]
                    if same_level_nodes:
                        sibling = np.random.choice(same_level_nodes)
                        graph.add_edge(node_name, sibling, "related_to", weight=0.5)
        
        # –ú–µ–∂–¥–æ–º–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏
        if node_id > 0:
            prev_domain = domains[node_id - 1]
            weight = 0.3 + np.random.random() * 0.4
            graph.add_edge(f"{prev_domain}_root", f"{domain}_root", "influences", weight=weight)
        
        node_id += 1
    
    print(f"–°–æ–∑–¥–∞–Ω –±–æ–ª—å—à–æ–π –≥—Ä–∞—Ñ —Å {len(graph.get_all_nodes())} —É–∑–ª–∞–º–∏ –∏ {len(graph.get_all_edges())} —Å–≤—è–∑—è–º–∏")
    return graph


def experiment_with_large_graph():
    """–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –±–æ–ª—å—à–∏–º –≥—Ä–∞—Ñ–æ–º."""
    
    print("\n=== –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –±–æ–ª—å—à–∏–º –≥—Ä–∞—Ñ–æ–º ===")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –±–æ–ª—å—à–æ–≥–æ –≥—Ä–∞—Ñ–∞
    large_graph = create_larger_test_graph(100)
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    initial_nodes = {"science_root": 1.0, "technology_root": 0.8}
    
    configs_to_test = {
        "fast": create_fast_config(),
        "default": create_default_config(),
        "precise": create_precise_config()
    }
    
    engine = create_default_engine(large_graph)
    
    for config_name, config in configs_to_test.items():
        print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ '{config_name}' –Ω–∞ –±–æ–ª—å—à–æ–º –≥—Ä–∞—Ñ–µ:")
        
        start_time = time.time()
        result = engine.propagate(initial_nodes, config)
        end_time = time.time()
        
        if result.success:
            print(f"  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {end_time - start_time:.3f}—Å")
            print(f"  –ò—Ç–µ—Ä–∞—Ü–∏–π: {result.iterations_used}")
            print(f"  –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤: {len(result.activated_nodes)}")
            print(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –æ–±—â–µ–≥–æ: {len(result.activated_nodes) / len(large_graph.get_all_nodes()) * 100:.1f}%")
            print(f"  –°—Ö–æ–¥–∏–º–æ—Å—Ç—å: {'–î–∞' if result.convergence_achieved else '–ù–µ—Ç'}")
        else:
            print(f"  –û—à–∏–±–∫–∞: {result.error_message}")
        
        engine.reset_activations()


def run_extended_examples():
    """–ó–∞–ø—É—Å–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤."""
    
    print("\nüî¨ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã")
    print("=" * 50)
    
    try:
        experiment_with_large_graph()
        
        print("\n‚úÖ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö: {e}")


# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
if __name__ == "__main__":
    main()
    run_extended_examples()